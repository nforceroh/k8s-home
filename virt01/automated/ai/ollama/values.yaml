---
ollama:
  image:
    repository: harbor.nf.lab/proxy.docker.io/ollama/ollama
  ollama:
    gpu:
      enabled: true
      type: 'nvidia'
    models:
      - mistral
      - llama3.1
      - llama3.2
      - llama3.2-vision
      - codellama

  runtimeClassName: "nvidia"
  ingress:
    enabled: true
    annotations:
      cert-manager.io/cluster-issuer: nf-lab
      cert-manager.io/private-key-rotation-policy: Always
      traefik.ingress.kubernetes.io/router.entrypoints: web,websecure  
      kubernetes.io/ingress.class: traefik
      external-dns.alpha.kubernetes.io/target: traefik.k3s.nf.lab
    hosts:
    - host: ollama.k3s.nf.lab
      paths:
        - path: /
          pathType: Prefix
    tls:
    - hosts:
      - ollama.k3s.nf.lab
      secretName: ollama-tls
  serviceAccount:
    create: true
    automount: true
    name: ollama-sa
  persistentVolume:
    enabled: true
    existingClaim: ollama
    size: 50Gi

