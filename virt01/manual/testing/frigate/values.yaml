
frigate:
  image:
    # -- Docker registry/repository to pull the image from
    repository: ghcr.io/blakeblackshear/frigate
    tag: stable-tensorrt

  envFromSecrets:
    - frigate-config
  gpu:
    nvidia:
      # -- Enables NVIDIA GPU compatibility. Must also use the "amd64nvidia" tagged image
      enabled: true
      runtimeClassName: nvidia
  ingress:
    # -- Enables the use of an Ingress Controller to front the Service and can provide HTTPS
    enabled: true    
    ingressClassName: "traefik"
    annotations:
      cert-manager.io/cluster-issuer: "nf-lab"
      cert-manager.io/private-key-rotation-policy: "Always"
      traefik.ingress.kubernetes.io/router.entrypoints: "websecure"
      external-dns.alpha.kubernetes.io/target: "traefik.k3s.nf.lab"
    hosts:
      - host: "frigate.k3s.nf.lab"
        paths:
          - path: '/'
            portName: http
    tls:
      - secretName: "frigate-tls"
        hosts:
          - "frigate.k3s.nf.lab"

  persistence:
    config:
      enabled: true        
      skipuninstall: false
      size: 10Gi
    media:
      enabled: true        
      skipuninstall: false    
      size: 50Gi
  config: |
    mqtt:
      # Required: host name
      host: mqtt.k3s.nf.lab
      # Optional: port (default: shown below)
      port: 1883
      # Optional: topic prefix (default: shown below)
      # WARNING: must be unique if you are running multiple instances
      topic_prefix: frigate
      # Optional: client id (default: shown below)
      # WARNING: must be unique if you are running multiple instances
      client_id: frigate
      # Optional: user
      #user: mqtt_user
      # Optional: password
      # NOTE: Environment variables that begin with 'FRIGATE_' may be referenced in {}.
      #       eg. password: '{FRIGATE_MQTT_PASSWORD}'
      #password: password
      # Optional: interval in seconds for publishing stats (default: shown below)
      stats_interval: 60

    go2rtc:
      streams:
        #Wyze
        LivingRoom:
          - rtsp://10.40.1.42:8554/1080p?mp4
          - ffmpeg:LivingRoom#audio=opus
        LivingRoom_sub:
          - rtsp://10.40.1.42:8554/360p?mp4
          - ffmpeg:LivingRoom#audio=opus
        FrontPorch:
          - rtsp://10.40.1.22:8554/1080p?mp4
          - ffmpeg:FrontPorch#audio=opus
        FrontPorch_sub:
          - rtsp://10.40.1.22:8554/360p?mp4
          - ffmpeg:FrontPorch#audio=opus
        BunCam:
          - rtsp://10.40.1.19:8554/1080p?mp4
          - ffmpeg:BunCam#audio=opus
        BunCam_sub:
          - rtsp://10.40.1.19:8554/360p?mp4
          - ffmpeg:BunCam#audio=opus
        Kitchen:
          - rtsp://scrypted-rtsp-svc:33759/75e57ba83105f666
          - ffmpeg:Kitchen#audio=opus
        Kitchen_sub:
          - rtsp://scrypted-rtsp-svc:33759/31e5716887d9312a
          - ffmpeg:Kitchen#audio=opus
        SittingRoom:
          - rtsp://scrypted-rtsp-svc:40123/0646b22eadf4d50a
          - ffmpeg:SittingRoom#audio=opus
        SittingRoom_sub:
          - rtsp://scrypted-rtsp-svc:40123/91389e5f43812d1a
          - ffmpeg:SittingRoom#audio=opus
        # reolink
        rlc_520a_main_garage:
          - rtsp://{FRIGATE_RTSP_USERNAME}:{FRIGATE_RTSP_PASSWORD}@10.40.1.149:554/h265Preview_01_main
        rlc_520a_sub_garage:
          - rtsp://{FRIGATE_RTSP_USERNAME}:{FRIGATE_RTSP_PASSWORD}@10.40.1.149:554/h265Preview_01_sub


    snapshots:
      enabled: true

    live:
      # Optional: Set the streams configured in go2rtc
      # that should be used for live view in frigate WebUI. (default: name of camera)
      # NOTE: In most cases this should be set at the camera level only.
      # streams:
      #   main_stream: main_stream_name
      #   sub_stream: sub_stream_name
      # Optional: Set the height of the jsmpeg stream. (default: 720)
      # This must be less than or equal to the height of the detect stream. Lower resolutions
      # reduce bandwidth required for viewing the jsmpeg stream. Width is computed to match known aspect ratio.
      height: 640
      # Optional: Set the encode quality of the jsmpeg stream (default: shown below)
      # 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
      quality: 8

    birdseye:
      enabled: true
      mode: continuous

    # objects:
    #   track:
    #     - person
    #     - car

    detect:
      enabled: true
      width: 640
      height: 480
      fps: 5
      min_initialized: 2
      max_disappeared: 25
      stationary:
        # Optional: Frequency for confirming stationary objects (default: same as threshold)
        # When set to 1, object detection will run to confirm the object still exists on every frame.
        # If set to 10, object detection will run to confirm the object still exists on every 10th frame.
        interval: 50
        # Optional: Number of frames without a position change for an object to be considered stationary (default: 10x the frame rate or 10s)
        threshold: 50
            
    ffmpeg:
      global_args: -hide_banner -loglevel warning -threads 2
      hwaccel_args: preset-nvidia
      input_args: preset-rtsp-generic
      output_args:
        detect: -threads 2 -f rawvideo -pix_fmt yuv420p
        record: preset-record-generic
      retry_interval: 10

    detectors:
      onnx:
        type: onnx

    model:
      # model_type: yolox
      # width: 640
      # height: 640
      # input_tensor: nchw
      # input_dtype: float_denorm
      # path: /config/model_cache/yolox_l.onnx
      model_type: yolonas
      width: 320 # <--- should match whatever was set in notebook
      height: 320 # <--- should match whatever was set in notebook
      input_pixel_format: bgr
      input_tensor: nchw
      path: /config/model_cache/yolo_nas_s.onnx
      labelmap_path: /labelmap/coco-80.txt

    objects:
      track:
        - person
        - car
        - dog
        - cat

      filters:
        dog:
          min_score: .7
          threshold: .9
        cat:
          min_score: .65
          threshold: .8
        person:
          min_score: .65
          threshold: .85
        car:
          min_score: .65
          threshold: .85
          
    # # NOTE: Can be overridden at the camera level
    # audio:
    #   # Optional: Enable audio events (default: shown below)
    #   enabled: False
    #   # Optional: Configure the amount of seconds without detected audio to end the event (default: shown below)
    #   max_not_heard: 30
    #   # Optional: Configure the min rms volume required to run audio detection (default: shown below)
    #   # As a rule of thumb:
    #   #  - 200 - high sensitivity
    #   #  - 500 - medium sensitivity
    #   #  - 1000 - low sensitivity
    #   min_volume: 500
    #   # Optional: Types of audio to listen for (default: shown below)
    #   listen:
    #     - bark
    #     - fire_alarm
    #     - scream
    #     - speech
    #     - yell
    #   # Optional: Filters to configure detection.
    #   filters:
    #     # Label that matches label in listen config.
    #     speech:
    #       # Minimum score that triggers an audio event (default: shown below)
    #       threshold: 0.8

    # review:
    #   # Optional: alerts configuration
    #   alerts:
    #     # Optional: enables alerts for the camera (default: shown below)
    #     enabled: True
    #     # Optional: labels that qualify as an alert (default: shown below)
    #     labels:
    #       - car
    #       - person
    #     # Optional: required zones for an object to be marked as an alert (default: none)
    #     # NOTE: when settings required zones globally, this zone must exist on all cameras
    #     #       or the config will be considered invalid. In that case the required_zones
    #     #       should be configured at the camera level.
    #     #required_zones:
    #     #  - driveway
    #   # Optional: detections configuration
    #   detections:
    #     # Optional: enables detections for the camera (default: shown below)
    #     enabled: True
    #     # Optional: labels that qualify as a detection (default: all labels that are tracked / listened to)
    #     labels:
    #       - car
    #       - person


    # genai:
    #   # Optional: Enable AI description generation (default: shown below)
    #   enabled: false
    #   # Required if enabled: Provider must be one of ollama, gemini, or openai
    #   provider: ollama
    #   model: llama3.2-vision:latest
    #   # Required if provider is ollama. May also be used for an OpenAI API compatible backend with the openai provider.
    #   base_url: http://ollama.ai.svc.cluster.local:11434
    #   # Required if gemini or openai
    #   api_key: ""
    #   # Optional: The default prompt for generating descriptions. Can use replacement
    #   # variables like "label", "sub_label", "camera" to make more dynamic. (default: shown below)
    #   prompt: "Describe the {label} in the sequence of images with as much detail as possible. Do not describe the background."
    #   # Optional: Object specific prompts to customize description results
    #   # Format: {label}: {prompt}
    #   object_prompts:
    #     person: "My special person prompt."

    cameras:
      # Name of your camera
      LivingRoom:
        enabled: true
        detect:
          enabled: false
        ffmpeg:
          inputs:
            - path: rtsp://127.0.0.1:8554/LivingRoom
              input_args: preset-rtsp-restream
              roles:
                - audio
                - record
            - path: rtsp://127.0.0.1:8554/LivingRoom_sub
              input_args: preset-rtsp-restream
              roles:
                - detect
        motion:
          mask: 
            - 0.396,0,0.393,0.119,0.624,0.162,0.621,0   
        mqtt:
          enabled: true
          timestamp: false
          bounding_box: false
          crop: true
          height: 720
          quality: 70
      FrontPorch:
        enabled: true
        detect:
          enabled: false
        ffmpeg:
          inputs:
            - path: rtsp://127.0.0.1:8554/FrontPorch
              input_args: preset-rtsp-restream
              roles:
                - audio
                - record
            - path: rtsp://127.0.0.1:8554/FrontPorch_sub
              input_args: preset-rtsp-restream
              roles:
                - detect
      BunCam:
        enabled: true
        detect:
          enabled: false
        ffmpeg:
          inputs:
            - path: rtsp://127.0.0.1:8554/BunCam
              input_args: preset-rtsp-restream
              roles:
                - audio
                - record
            - path: rtsp://127.0.0.1:8554/BunCam_sub
              input_args: preset-rtsp-restream
              roles:
                - detect
      Kitchen:
        enabled: true
        detect:
          enabled: false
        ffmpeg:
          inputs:
            - path: rtsp://127.0.0.1:8554/Kitchen
              input_args: preset-rtsp-restream
              roles:
                - audio
                - record
            - path: rtsp://127.0.0.1:8554/Kitchen_sub
              input_args: preset-rtsp-restream
              roles:
                - detect
      SittingRoom:
        enabled: true
        detect:
          enabled: false
        ffmpeg:
          inputs:
            - path: rtsp://127.0.0.1:8554/SittingRoom
              input_args: preset-rtsp-restream
              roles:
                - audio
                - record
            - path: rtsp://127.0.0.1:8554/SittingRoom_sub
              input_args: preset-rtsp-restream
              roles:
                - detect
      # Reolink Rlc 520a
      garage_front:
        enabled: true
        live:
          streams:
            main_stream: rlc_520a_main_garage
            sub_stream: rlc_520a_sub_garage
        ffmpeg:
          inputs:
            - path: rtsp://127.0.0.1:8554/rlc_520a_main_garage
              input_args: preset-rtsp-restream
              roles:
                - audio
                - record
            - path: rtsp://127.0.0.1:8554/rlc_520a_sub_garage
              input_args: preset-rtsp-restream
              roles:
                - detect
        motion:
          mask: 
            - 0.478,0.223,0.444,0.329,0.492,0.354,0.548,0.331,0.55,0.272,0.523,0.215,0.5,0.185
            - 0.038,0.353,0.106,0.46,0.052,0.483,0.004,0.487,0.002,0.358
            - 0.124,0.136,0.132,0.299,0.008,0.313,0.002,0.263
            - 0.201,0.116,0.189,0.239,0.262,0.245,0.319,0.215,0.311,0.171,0.347,0.18,0.432,0.235,0.509,0.171,0.626,0.164,0.64,0.23,0.745,0.219,0.737,0.159,0.772,0.136,0.875,0.146,0.89,0.194,0.941,0.214,0.957,0.251,0.999,0.265,1,0.128,0.885,0.093,0.674,0.037,0.504,0.032,0.351,0.119,0.312,0.11,0.264,0.074
            - 0.012,0.95,0.011,0.981,0.344,0.983,0.344,0.951
        review:
          alerts:
            labels: []
        # From the sub stream we have a resolution: 640x480, fps: 7, bitrate: 512
        detect:
          enabled: true
          fps: 7
          width: 640
          height: 480
        objects:
          track:
            - person
            - face
            - car
            - license_plate
            - dog
            - cat
            - deer
            - ups
            - fedex
            - amazon
            - package
        record:
          enabled: False
          retain:
            days: 7
            mode: motion
          alerts:
            retain:
              days: 14
              mode: active_objects
          detections:
            retain:
              days: 14
              mode: active_objects

    telemetry:
      # Optional: Enabled network interfaces for bandwidth stats monitoring (default: empty list, let nethogs search all)
      network_interfaces:
        - eth
        - enp
        - eno
        - ens
        - wl
        - lo
      # Optional: Configure system stats
      stats:
        network_bandwidth: true
      # Optional: Enable the latest version outbound check (default: shown below)
      # NOTE: If you use the Home Assistant integration, disabling this will prevent it from reporting new versions
      version_check: true

    version: 0.16-0    
